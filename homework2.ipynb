{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c513df-b49f-447f-a8cf-6e1c775a34eb",
      "metadata": {
        "id": "17c513df-b49f-447f-a8cf-6e1c775a34eb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "import argparse\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d26ae6b5-afcd-4463-83f7-16550a73e02f",
      "metadata": {
        "id": "d26ae6b5-afcd-4463-83f7-16550a73e02f",
        "outputId": "5b8cd872-1dad-4364-cbb1-3911c07bc2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE_PATH: C:\\Users\\USER\\git\\link_dl\\_03_homeworks\\homework_2\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "BASE_PATH = Path.cwd()\n",
        "print(\"BASE_PATH:\", BASE_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f677ec23-ebb5-493a-860d-0e56aedcac83",
      "metadata": {
        "id": "f677ec23-ebb5-493a-860d-0e56aedcac83"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(BASE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1ef683-f39c-48f6-9668-0a748bbd869c",
      "metadata": {
        "id": "7a1ef683-f39c-48f6-9668-0a748bbd869c"
      },
      "outputs": [],
      "source": [
        "from titanic_dataset import get_preprocessed_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0613bc54-affe-41dc-b6ec-cb5654950cb2",
      "metadata": {
        "id": "0613bc54-affe-41dc-b6ec-cb5654950cb2"
      },
      "source": [
        "# 데이터 로더 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2fed0a9-e73d-4752-b924-3efb869db940",
      "metadata": {
        "id": "e2fed0a9-e73d-4752-b924-3efb869db940"
      },
      "source": [
        "#### 데이터셋 불러와 학습·검증·테스트용 DataLoader 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120fb285-b5ad-47f9-a3cd-c996c574fa2d",
      "metadata": {
        "id": "120fb285-b5ad-47f9-a3cd-c996c574fa2d"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
        "    print(f\"Train: {len(train_dataset)}, Validation: {len(validation_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
        "    validation_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset), shuffle=False)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f4fba10-bc42-47b0-a125-6e97b854c2ed",
      "metadata": {
        "id": "7f4fba10-bc42-47b0-a125-6e97b854c2ed"
      },
      "source": [
        "# 입력 차원과 출력 차원, 활성화함수에 따라 3층 신경망 모델 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e50e68-4683-4e3b-b10e-e004302ed204",
      "metadata": {
        "id": "b3e50e68-4683-4e3b-b10e-e004302ed204"
      },
      "source": [
        "#### PyTorch nn.Module과 nn.Sequential을 사용한 다층 퍼셉트론 방식으로 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9eef61a-9b17-4896-80c4-ecf618ee635b",
      "metadata": {
        "id": "b9eef61a-9b17-4896-80c4-ecf618ee635b"
      },
      "outputs": [],
      "source": [
        "class MyTitanicModel(nn.Module):\n",
        "    def __init__(self, n_input, n_output, activation_fn):\n",
        "        super().__init__()\n",
        "\n",
        "        act_fn = {\n",
        "            \"relu\": nn.ReLU(),\n",
        "            \"sigmoid\": nn.Sigmoid(),\n",
        "            \"elu\": nn.ELU(),\n",
        "            \"leakyrelu\": nn.LeakyReLU()\n",
        "        }[activation_fn.lower()]\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
        "            act_fn,\n",
        "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
        "            act_fn,\n",
        "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384807dd-8ea4-4cc6-b785-95427b8e0c71",
      "metadata": {
        "id": "384807dd-8ea4-4cc6-b785-95427b8e0c71"
      },
      "source": [
        "# 모델과 Adam 옵티마이저를 생성해 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5be794d-ce30-468c-acfd-afa0e5fe276f",
      "metadata": {
        "id": "a5be794d-ce30-468c-acfd-afa0e5fe276f"
      },
      "outputs": [],
      "source": [
        "def get_model_and_optimizer(n_input):\n",
        "    model = MyTitanicModel(n_input=n_input, n_output=1, activation_fn=wandb.config.activation)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
        "    return model, optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44390e5a-bb1f-4bf9-9bb9-c397e4fb652a",
      "metadata": {
        "id": "44390e5a-bb1f-4bf9-9bb9-c397e4fb652a"
      },
      "source": [
        "# 모델을 학습하고 검증 손실을 계산하며, 결과를 wandb에 로깅하는 학습 루프"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67763a7c-77f0-4318-80f9-00f383a43259",
      "metadata": {
        "id": "67763a7c-77f0-4318-80f9-00f383a43259"
      },
      "source": [
        "#### 손실 함수: BCEWithLogitsLoss (이진 분류용)\n",
        "\n",
        "#### 학습: train_loader로 미니배치 학습 → optimizer.zero_grad() → loss.backward() → optimizer.step() 순서\n",
        "\n",
        "#### 검증: valid_loader로 평가, torch.no_grad() 사용\n",
        "\n",
        "#### 로그: wandb.log로 epoch별 학습·검증 손실 기록\n",
        "\n",
        "#### 출력: 일정 epoch마다 학습/검증 손실 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0940aa-e93a-4f10-9b06-67434e91d19b",
      "metadata": {
        "id": "9e0940aa-e93a-4f10-9b06-67434e91d19b"
      },
      "outputs": [],
      "source": [
        "def training_loop(model, optimizer, train_loader, valid_loader):\n",
        "    n_epochs = wandb.config.epochs\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    next_print_epoch = 50\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            X, y = batch[\"input\"], batch[\"target\"].float().unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_loader:\n",
        "                X, y = batch[\"input\"], batch[\"target\"].float().unsqueeze(1)\n",
        "                y_pred = model(X)\n",
        "                loss = loss_fn(y_pred, y)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss / len(train_loader),\n",
        "            \"val_loss\": val_loss / len(valid_loader)\n",
        "        })\n",
        "\n",
        "        if epoch % next_print_epoch == 0:\n",
        "            print(f\"Epoch {epoch}: train_loss={train_loss / len(train_loader):.4f}, val_loss={val_loss / len(valid_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8a6d12c-1ee9-427b-a406-04e946b7ee54",
      "metadata": {
        "id": "f8a6d12c-1ee9-427b-a406-04e946b7ee54"
      },
      "source": [
        "# 모델로 테스트 데이터를 예측해 이진 레이블 생성 후 CSV 제출 파일로 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79876e99-4d1b-40ec-9455-68d80dd48619",
      "metadata": {
        "id": "79876e99-4d1b-40ec-9455-68d80dd48619"
      },
      "source": [
        "#### model.eval()과 torch.no_grad()로 테스트 데이터 예측\n",
        "\n",
        "#### torch.sigmoid로 확률 변환 후 0.5 기준 이진 레이블 결정\n",
        "\n",
        "#### 결과를 pandas.DataFrame으로 만들어 CSV 파일로 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "095874d1-f143-4e1b-8eb6-b900f8676b4f",
      "metadata": {
        "id": "095874d1-f143-4e1b-8eb6-b900f8676b4f"
      },
      "outputs": [],
      "source": [
        "def generate_submission(model, test_loader, output_path=\"submission.csv\"):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            X = batch[\"input\"]\n",
        "            y_pred = model(X)\n",
        "            y_prob = torch.sigmoid(y_pred)\n",
        "            y_label = (y_prob >= 0.5).int().squeeze()\n",
        "            all_preds.extend(y_label.tolist())\n",
        "\n",
        "    passenger_ids = list(range(892, 892 + len(all_preds)))  # Titanic test set ID 범위\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        \"PassengerId\": passenger_ids,\n",
        "        \"Survived\": all_preds\n",
        "    })\n",
        "    submission.to_csv(output_path, index=False)\n",
        "    print(f\"✅ Submission file saved: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081e1af8-4d03-4d60-8b32-bebd8e971910",
      "metadata": {
        "id": "081e1af8-4d03-4d60-8b32-bebd8e971910"
      },
      "source": [
        "# 데이터 로드, 모델 생성·학습, 테스트 예측 후 wandb로 실험 기록하고 제출 CSV 생성까지 전체 파이프라인 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c02fe2-7866-4575-a301-248e981f9514",
      "metadata": {
        "id": "f3c02fe2-7866-4575-a301-248e981f9514"
      },
      "source": [
        "### 파이프라인 기반 순차 실행 방식\n",
        "\n",
        "#### wandb로 실험 설정/로그 초기화\n",
        "\n",
        "#### 데이터 로드 → 모델 및 옵티마이저 생성 → 학습 루프 수행\n",
        "\n",
        "#### 테스트 데이터 예측 → CSV 제출 파일 생성\n",
        "\n",
        "#### wandb 실험 종료"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d0aed26-5788-41ec-8e1b-7ffc576478e7",
      "metadata": {
        "id": "4d0aed26-5788-41ec-8e1b-7ffc576478e7"
      },
      "outputs": [],
      "source": [
        "def main(args):\n",
        "    current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "    config = {\n",
        "        'epochs': args.epochs,\n",
        "        'batch_size': args.batch_size,\n",
        "        'learning_rate': 1e-3,\n",
        "        'n_hidden_unit_list': [32, 16],\n",
        "        'activation': args.activation\n",
        "    }\n",
        "\n",
        "    wandb.init(\n",
        "        mode=\"online\" if args.wandb else \"disabled\",\n",
        "        project=\"titanic_training\",\n",
        "        entity=\"jjw122601-koreatech\",\n",
        "        notes=\"Titanic survival prediction\",\n",
        "        tags=[\"titanic\", \"binary_classification\"],\n",
        "        name=current_time_str,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    train_loader, valid_loader, test_loader = get_data()\n",
        "    sample_batch = next(iter(train_loader))\n",
        "    n_input = sample_batch[\"input\"].shape[1]\n",
        "    print(f\"Detected n_input = {n_input}\")\n",
        "\n",
        "    model, optimizer = get_model_and_optimizer(n_input)\n",
        "    training_loop(model, optimizer, train_loader, valid_loader)\n",
        "\n",
        "    output_csv = f\"submission_{wandb.config.activation}_b{wandb.config.batch_size}.csv\"\n",
        "    generate_submission(model, test_loader, output_path=output_csv)\n",
        "\n",
        "    wandb.finish()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9220b6ea-0bef-4059-98a9-c5987ccce536",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "9220b6ea-0bef-4059-98a9-c5987ccce536"
      },
      "source": [
        " ![이미지](https://i.ifh.cc/DOvsP4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0521aac3-a1c0-4741-ad44-a41570cb39fc",
      "metadata": {
        "id": "0521aac3-a1c0-4741-ad44-a41570cb39fc"
      },
      "source": [
        "## 명령행 인자를 받아 학습 설정을 지정하고, main 함수로 전체 학습·예측 파이프라인 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "182d8501-5059-40c9-bb71-7ca110d3d1af",
      "metadata": {
        "id": "182d8501-5059-40c9-bb71-7ca110d3d1af",
        "outputId": "d6ffcaa3-54a7-4063-b299-648a707f741e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--wandb | --no-wandb] [-b BATCH_SIZE] [-e EPOCHS] [-a {relu,sigmoid,elu,leakyrelu}]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\USER\\AppData\\Roaming\\jupyter\\runtime\\kernel-0af2efc6-4138-405e-8afa-76c63b708191.json\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "2",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--wandb\", action=argparse.BooleanOptionalAction, default=False)\n",
        "    parser.add_argument(\"-b\", \"--batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"-e\", \"--epochs\", type=int, default=200)\n",
        "    parser.add_argument(\"-a\", \"--activation\", type=str, default=\"relu\",\n",
        "                        choices=[\"relu\", \"sigmoid\", \"elu\", \"leakyrelu\"],\n",
        "                        help=\"Activation function\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "118756bd-2bdc-4ffc-9a1e-ebd36666800d",
      "metadata": {
        "id": "118756bd-2bdc-4ffc-9a1e-ebd36666800d"
      },
      "source": [
        "# 숙제 후기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c3652a-12ad-49d3-915c-f3d9950bcc65",
      "metadata": {
        "id": "57c3652a-12ad-49d3-915c-f3d9950bcc65"
      },
      "source": [
        "### 이번 프로젝트에서는 Titanic 데이터셋을 이용해 생존 여부를 예측하는 3층 다층 퍼셉트론 모델을 구현했습니다. 데이터는 전처리 후 학습, 검증, 테스트용으로 나누고 DataLoader로 배치 단위로 불러왔으며, BCEWithLogitsLoss로 학습하고 검증 손실을 wandb로 기록했습니다. 학습 후 테스트 데이터를 예측해 sigmoid로 이진 레이블을 만들고 CSV 파일로 저장했습니다. 특히 손실이 불안정하게 변동하거나 학습 속도와 배치 크기, 활성화 함수 선택으로 모델 성능 최적화가 어려웠지만, 여러 실험을 반복하며 하이퍼파라미터를 조정하고 wandb 기록을 참고하여 최적의 설정을 찾아 문제를 해결할 수 있었습니다."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pycharm_dl",
      "language": "python",
      "name": "link_dl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}